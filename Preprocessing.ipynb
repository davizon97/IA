{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary:** Data preprocessing is used to improve the quality of the data and prepare it for analysis or modeling. Specifically, it includes several tasks that allow data to be cleaned, transformed, and organized so that it is suitable for use in analysis or machine learning algorithms.\n",
        "\n",
        "Considerations:\n",
        "\n",
        "\n",
        "1. Missing data (NA, nan, null)\n",
        "2. Repeated values\n",
        "3. Outliers\n",
        "4. Irrelevant/Redundant columns\n",
        "5. Single-level categorical column/Single-value numerical column\n",
        "6. Typographical errors/Change the values of some elements\n",
        "7. Change datatype\n",
        "\n"
      ],
      "metadata": {
        "id": "8_Vcbh6flgmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Missing data**\n",
        "\n",
        "We have two options, but the decision requires an analysis of the data:\n",
        "\n",
        "\n",
        "1. Remove missing data\n",
        "2. Impute data\n",
        "\n"
      ],
      "metadata": {
        "id": "CJCkqGh_nRpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nans = df.isna().sum()\n",
        "print(nans)"
      ],
      "metadata": {
        "id": "gNQqZXn37Egc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove missing data:\n",
        "\n",
        "*   When there is enough data and removing the missing ones doesn't have an impact\n",
        "*   When there are few missing values to be removed\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vflpVc3KoIzg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLyuPJ6clHV0"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impute data:\n",
        "\n",
        "\n",
        "*   Replace the missing values with the mean of each column.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ko2Dc_3tobQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(df.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "BvdFef4qoIQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Simple interpolation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vAIei1SuqGYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['A', 'B', 'C']\n",
        "df[columns] = df[columns].interpolate(method='linear', limit_direction='forward', axis=0)"
      ],
      "metadata": {
        "id": "cQ2sC_xsnRMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Repeated values**\n",
        "\n",
        "This consists in remove the repeated rows in the dataframe"
      ],
      "metadata": {
        "id": "gzlC4WPhrQkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "fkttyQ8NrinO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outliers**\n",
        "\n",
        "Handling outliers in a DataFrame is an important task in data preprocessing, as they can significantly affect analyses and predictive models. Here are several common techniques for dealing with outliers, depending on the situation and the type of data"
      ],
      "metadata": {
        "id": "sqE894Qyrxn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Identifying Outliers\n",
        "\n",
        "We can identify outliers using various methods, such as the interquartile range (IQR), z-score, or simply through visualization (e.g., boxplots).\n",
        "\n",
        "The IQR is the range between the first quartile (Q1) and the third quartile (Q3). A value that falls outside 1.5 times the IQR is considered an outlier."
      ],
      "metadata": {
        "id": "mTkOSqPszMAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'A': [10, 12, 14, 15, 100],  # The value 100 is a potential outlier\n",
        "    'B': [1, 2, 2, 3, 100]       # The value 100 is a potential outlier\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the interquartile range (IQR) for column A\n",
        "Q1 = df['A'].quantile(0.25)  # First quartile (25%)\n",
        "Q3 = df['A'].quantile(0.75)  # Third quartile (75%)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define the bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identify outliers\n",
        "outliers = df[(df['A'] < lower_bound) | (df['A'] > upper_bound)]\n",
        "print(\"Outliers:\\n\", outliers)"
      ],
      "metadata": {
        "id": "oPIcOJE0r3gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Removing Outliers\n",
        "\n",
        "Once identified, you can remove outliers by filtering the DataFrame to keep only the values within the defined bounds."
      ],
      "metadata": {
        "id": "XiOzpVRNzZyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to remove outliers in column A\n",
        "df_filtered = df[(df['A'] >= lower_bound) & (df['A'] <= upper_bound)]\n",
        "print(\"DataFrame without outliers:\\n\", df_filtered)"
      ],
      "metadata": {
        "id": "HvB4Twm0zcLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Replacing Outliers\n",
        "\n",
        "Another option is to replace outliers with more manageable values, such as the mean or median of the column.\n",
        "\n",
        "Example: Replacing Outliers with the Median"
      ],
      "metadata": {
        "id": "5_Qzr0VazfIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace outliers in column A with the median of the column\n",
        "median = df['A'].median()\n",
        "df['A'] = np.where((df['A'] < lower_bound) | (df['A'] > upper_bound), median, df['A'])\n",
        "print(\"DataFrame with outliers replaced:\\n\", df)"
      ],
      "metadata": {
        "id": "O2ILBwQozfOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Applying Transformations (Scaling or Normalization)\n",
        "\n",
        "If you do not want to remove or modify outliers, you can apply transformations that reduce their impact, such as normalization or logarithmic scaling."
      ],
      "metadata": {
        "id": "D3zdfObzzny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['A'] = np.log1p(df['A'])  # log(1 + A), to avoid issues with 0 or negative values"
      ],
      "metadata": {
        "id": "bMemhrDzzn69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Winsorization\n",
        "\n",
        "Winsorization is a technique where extreme values are replaced by the nearest value within a defined percentile limit, reducing the impact of outliers without removing them completely."
      ],
      "metadata": {
        "id": "2nStH4Arz0MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mstats\n",
        "\n",
        "# Winsorize to limit outliers to the 5th and 95th percentiles\n",
        "df['A'] = mstats.winsorize(df['A'], limits=[0.05, 0.05])"
      ],
      "metadata": {
        "id": "NUgp8Uugz0a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Detecting Outliers with Z-Score\n",
        "\n",
        "Another way is to use the z-score to calculate how far values are from the mean in terms of standard deviations."
      ],
      "metadata": {
        "id": "-Cfs7HcB0HqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Calculate the z-score for each value in column A\n",
        "z_scores = np.abs(stats.zscore(df['A']))\n",
        "\n",
        "# Set a threshold for outliers (e.g., z > 3)\n",
        "outliers = df[z_scores > 3]\n",
        "print(\"Outliers with z-score:\\n\", outliers)"
      ],
      "metadata": {
        "id": "alI-sFRz0Hxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Visualizing Outliers\n",
        "\n",
        "You can use plots like boxplots or scatter plots to easily visualize outliers."
      ],
      "metadata": {
        "id": "KOdc60w-0Kdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a boxplot to visualize outliers\n",
        "plt.boxplot(df['A'])\n",
        "plt.title('Boxplot of Column A')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WUyrfmjc0KkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Irrelevant/Redundant columns**\n",
        "\n",
        "This consists in remove the irrelevant or redundant columns from the dataframe"
      ],
      "metadata": {
        "id": "tSx9Ks4Jr4GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['A', 'C'], inplace=True)"
      ],
      "metadata": {
        "id": "MnzyksSEsCPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For categorical data, it is important to review the number of unique values ​​(sublevels) in each column"
      ],
      "metadata": {
        "id": "rW9bhk65sShH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_cat = ['A','B','C']\n",
        "\n",
        "for col in df.cols_cat:\n",
        "    print(f'Columna {col}: {df[col].nunique()} sublevels')"
      ],
      "metadata": {
        "id": "I0ECXALVsSq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Single-level categorical column/Single-value numerical column**\n",
        "\n",
        "Here we can delete rows using a filter for certain conditions"
      ],
      "metadata": {
        "id": "wSb5rXdMuUbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete rows where column B (categorical) is 'apple'\n",
        "df_filtered = df_filtered[df_filtered['B'] != 'apple']\n",
        "\n",
        "#Delete rows where column A (numeric) is greater than 3\n",
        "df_filtered = df[df['A'] <= 3]"
      ],
      "metadata": {
        "id": "In6Yu82mu9Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Typographical errors/Change the values of some elements**\n",
        "\n",
        "We can change the value of some of the elements of a column in a dataframe"
      ],
      "metadata": {
        "id": "No7EPOlSwuNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change 'Blu' and 'Bleu' to 'Blue'\n",
        "df['Color'] = df['Color'].replace({'Blu': 'Blue', 'Bleu': 'Blue'})\n",
        "\n",
        "#Change the values ​​of 'column1' that are greater than 30 to the value 100\n",
        "df.loc[df['column1'] > 30, 'column1'] = 100"
      ],
      "metadata": {
        "id": "iGYadcygwuv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Change datatype**\n",
        "\n",
        "*   A common case is when we have a column as \"object\" type and we want it to be numeric as integer or float\n",
        "*  Also, we can use it to change the Date column to datetime type\n",
        "\n"
      ],
      "metadata": {
        "id": "zpPGepnKyBPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['A'] = df['A'].astype(int)\n",
        "\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
        "\n",
        "df['Categoría'] = df['Categoría'].astype('category')"
      ],
      "metadata": {
        "id": "buPJDSPtyCVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}